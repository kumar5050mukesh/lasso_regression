{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is Lasso Regression, and how does it differ from other regression techniques?\n",
    "\"\"\"Lasso regression is a type of linear regression that is used for feature selection and regularization. \n",
    "It works by adding a penalty term to the standard linear regression cost function, which encourages the model \n",
    "to use fewer variables or features in the final regression equation . Lasso regression uses L1 regularization technique,\n",
    " which adds a penalty equal to the absolute value of the magnitude of coefficients. This can result in sparse models with\n",
    "   few coefficients; some coefficients can become zero and eliminated from the model .\n",
    "\n",
    "Lasso regression differs from other regression techniques such as Ridge regression, which uses L2 regularization technique\n",
    " that adds a penalty equal to the square of the magnitude of coefficients. Ridge regression shrinks the coefficients and \n",
    " helps to reduce model complexity and multicollinearity . \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. What is the main advantage of using Lasso Regression in feature selection?\n",
    "\"\"\"The main advantage of using Lasso Regression in feature selection is that it can shrink the coefficients of less important \n",
    "features to zero, effectively performing feature selection. This can result in a sparse model with fewer features, making the\n",
    " model more interpretable and potentially improving its performance by reducing the risk of overfitting.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. How do you interpret the coefficients of a Lasso Regression model?\n",
    "\"\"\"The coefficients of a Lasso Regression model can be interpreted in a similar way to those of a standard linear regression model.\n",
    " Each coefficient represents the change in the dependent variable for a one-unit change in the corresponding independent variable,\n",
    "   while holding all other independent variables constant. However, because Lasso Regression performs feature selection by shrinking\n",
    "     some coefficients to zero, it is important to note that a zero coefficient indicates that the corresponding feature has been \n",
    "     excluded from the model and is not considered important in predicting the dependent variable\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. What are the tuning parameters that can be adjusted in Lasso Regression, and how do they affect the\n",
    "# model's performance?\n",
    "\"\"\"In Lasso Regression, the main tuning parameter is the regularization parameter, often denoted by lambda or alpha. \n",
    "This parameter controls the strength of the L1 penalty term in the cost function. A larger value of lambda results in \n",
    "more shrinkage of the coefficients towards zero, leading to a sparser model with fewer features. On the other hand,\n",
    " a smaller value of lambda results in less shrinkage and a denser model with more features.\n",
    "\n",
    "The choice of lambda can have a significant impact on the modelâ€™s performance. If lambda is too large, the model may\n",
    "underfit the data and have high bias. If lambda is too small, the model may overfit the data and have high variance. \n",
    "The optimal value of lambda can be determined through cross-validation or other model selection techniques.\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. Can Lasso Regression be used for non-linear regression problems? If yes, how?\n",
    "\"\"\"Yes, Lasso Regression can be used for non-linear regression problems by incorporating non-linear transformations of \n",
    "the input features. For example, polynomial features  can be added to the model to capture non-linear \n",
    "relationships between the independent and dependent variables. Lasso Regression can then be applied to perform feature \n",
    "selection and shrink the coefficients of less important features to zero. This can result in a sparse model that includes\n",
    " only the most important non-linear terms.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. What is the difference between Ridge Regression and Lasso Regression?\n",
    "\"\"\"Ridge Regression and Lasso Regression are both types of linear regression that use regularization to improve model performance. \n",
    "The main difference between the two methods lies in the type of regularization used.\n",
    "\n",
    "Ridge Regression uses L2 regularization, which adds a penalty term to the cost function equal to the square of the magnitude of \n",
    "the coefficients. This has the effect of shrinking the coefficients towards zero, but not setting them exactly to zero. \n",
    "As a result, Ridge Regression does not perform feature selection and all features are retained in the model.\n",
    "\n",
    "Lasso Regression, on the other hand, uses L1 regularization, which adds a penalty term to the cost function equal to the\n",
    " absolute value of the magnitude of the coefficients. This can result in some coefficients being shrunk exactly to zero, \n",
    " effectively performing feature selection and excluding those features from the model.\n",
    "\n",
    " Ridge Regression is useful for reducing model complexity and multicollinearity by shrinking the coefficients\n",
    " towards zero, while Lasso Regression is useful for feature selection by setting some coefficients exactly to zero.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Can Lasso Regression handle multicollinearity in the input features? If yes, how?\n",
    "\"\"\"Yes, Lasso Regression can handle multicollinearity in the input features. When multicollinearity is present, \n",
    "the correlated features carry similar information and are not all necessary to include in the model.\n",
    " Lasso Regression can help to address this issue by shrinking the coefficients of some of the correlated features to zero, \n",
    " effectively performing feature selection and excluding those features from the model. This can result in a more parsimonious\n",
    "   model that includes only the most important features for predicting the dependent variable.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. How do you choose the optimal value of the regularization parameter (lambda) in Lasso Regression?\n",
    "\"\"\"The optimal value of the regularization parameter (lambda) in Lasso Regression can be determined through cross-validation\n",
    " or other model selection techniques. In cross-validation, the data is split into several subsets and the model is trained \n",
    " on some of these subsets and evaluated on the remaining subsets. This process is repeated for different values of lambda \n",
    " and the value that results in the best model performance, as measured by a chosen evaluation metric, is selected as the \n",
    " optimal value. Other model selection techniques such as grid search or Bayesian optimization can also be used to find \n",
    " the optimal value of lambda.\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
